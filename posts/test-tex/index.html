<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Inline math: 
\(\varphi\)


Displayed math:

$$\begin{aligned}
\varphi &\Rightarrow \psi \\
\varnothing &\rightarrow A
\end{aligned}$$


$$
R_{\mu \nu} - {1 \over 2}g_{\mu \nu},R + g_{\mu \nu} \Lambda
= {8 \pi G \over c^4} T_{\mu \nu}
$$
The equation $$(x_i \cdot x_j)^2$$ is called kernel function and is often written as $$k(x_i, x_j)$$.
$$
\arg\max_\alpha \sum_j \alpha_j - \frac{1}{2} \sum_{j,k} \alpha_j, \alpha_k y_j y_k (x_j \cdot x_k)
$$
$$
f(X) = \frac{1}{(2\pi)^{\frac{n}{2} |\Sigma|^{\frac{1}{2}}}} e^{ - \frac{1}{2} (X - \mu)^T \Sigma^{-1} (X - \mu)}
$$"><title>Test Tex
</title><link rel="shortcut icon" type=image/x-icon href=/><link rel=stylesheet href=/css/main.43df519ab066f59f1924d4549f768d2f2b0c9a15f3c4d0658e5dfd1e92ccbf565e160f6e560e1a6e3a34cd946b88e8217f177e7451580e913a8ec9169003f1fe.css integrity="sha512-Q99RmrBm9Z8ZJNRUn3aNLysMmhXzxNBljl39HpLMv1ZeFg9uVg4abjo0zZRriOghfxd+dFFYDpE6jskWkAPx/g=="><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body a=auto><main class=page-content aria-label=Content><div class=w><a href=/>..</a><article><h1>Test Tex</h1><p>Inline math: <span>\(\varphi\)</span></p><p>Displayed math:
<span>$$\begin{aligned}
\varphi &\Rightarrow \psi \\
\varnothing &\rightarrow A
\end{aligned}$$</span></p><p>$$
R_{\mu \nu} - {1 \over 2}g_{\mu \nu},R + g_{\mu \nu} \Lambda
= {8 \pi G \over c^4} T_{\mu \nu}
$$</p><p>The equation $$(x_i \cdot x_j)^2$$ is called kernel function and is often written as $$k(x_i, x_j)$$.</p><p>$$
\arg\max_\alpha \sum_j \alpha_j - \frac{1}{2} \sum_{j,k} \alpha_j, \alpha_k y_j y_k (x_j \cdot x_k)
$$</p><p>$$
f(X) = \frac{1}{(2\pi)^{\frac{n}{2} |\Sigma|^{\frac{1}{2}}}} e^{ - \frac{1}{2} (X - \mu)^T \Sigma^{-1} (X - \mu)}
$$</p><p>$$
\mu_i = \sum_{j=1}^N \frac{p_{ij} x}{n_i} \
\Sigma_i = \sum_{j=1}^N \frac{p_{ij} (x_j - \mu_i) (x_j - \mu_i)^T}{n_i}\
w_i = \frac{n_i}{N}
$$</p><p>$$
S_i^{(t)} = \big { x_p : \big | x_p - \mu^{(t)}_i \big |^2 \le \big | x_p - \mu^{(t)}_j \big |^2 \ \forall j, 1 \le j \le k \big}
$$</p><p>(The error above is a demo for incorrect formulas.)</p></article><a href=#top>top</a></div></main></body></html>